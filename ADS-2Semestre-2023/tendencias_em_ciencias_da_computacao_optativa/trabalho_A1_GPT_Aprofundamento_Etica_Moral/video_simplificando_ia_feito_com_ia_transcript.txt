Inteligência Artificial é uma área de estudos bem ampla no contexto de Tecnologia da Informação, na prática, é uma amalgama de técnicas de análise e estatística aplicada em vários conjuntos de dados, quanto maior a massa de dados, melhor será os resultados em observação.

Por isso apesar de ser uma área estudada a bastante tempo, desde os primórdios da Computação, pois por conta de sua natureza de necessitar possuir uma grande quantidade de dados para treinamentos (Machine learning) utilizando-os, para analisar os padrões e etc, isso só foi possível depois do BOOM da Internet, que possibilitou uma grande coleta de dados ao longo dos anos pelas Big Techs. (Google, Facebook, Instagram, Linkedin, Youtube, Twitter, e etc)

Para cada problema existe uma função matemática mais apropriada, desta forma quanto maior o conhecimento sobre elas, melhor. Isso ocorre devido aos tipos de dados em análise, pois os dados podem ser quantitativos ou qualitativos, e por isso vão existir diferentes tipos de funções matemáticas para melhor tratar e analisar esses dados. Dados Quantitativos: A idade de uma pessoa é um exemplo de dado quantitativo. Você pode realizar operações matemáticas, como média ou soma, sobre esses dados. Dados Qualitativos: O gênero de uma pessoa (masculino, feminino, não binário, etc.) é um dado qualitativo que descreve características, mas não pode ser numericamente representado, porisso eles são qualitativos e não quantitativos.

Por tanto, para obter um melhor aproveitamento do GPT é preciso entender como ele funciona por debaixo dos panos, mais especificamente deve-se entender os seguintes pontos:

- Como uma Inteligência Artificial generativa funciona (Cadeias de Markov que é o "pai" dessas Generativas mais modernas). Dado uma sequência de palavras, olhando para a palavra atual final, qual é a próxima palavra mais provável a aparecer? de acordo com o resultado o modelo "cospe" essa palavra e faz a mesma análise novamente, porém considerando agora também essa palavra "cuspida" como sendo a palavra atual final, e o ciclo vai se repetindo até atingir o limite de parâmetro do modelo. O limite de parâmetro do modelo é a quantidade de tokens (N-Grams) ou também palavras, que esse modelo consegue "memorizar" dado a sequência completa, ou seja, quantas palavras anteriores ele consegue levar em consideração na hora de realizar a probabilidade do conjunto completo. N-Grams, ou tokens, não são apenas "Palavras" simples, mas sim o que o modelo aprendeu durante o treinamento, isso implica que, o modelo não entende o que é a palavra, mas sim o que ela significa (transmite) nesta mensagem.

- Exemplo prático: Com Modelo de Ordem 1 (Memória de uma palavra): Para a seguinte palavra: "Oi", a próxima palavra mais provável a aparecer é: "tudo bem" (100% de chances). E NÃO: "Alface" (0% de chances). Quanto mais palavras anteriores considerar melhor será a coerência dos resultados, neste caso o novo GPT-4 vai considerar até 25 mil palavras anteriores.

- O que é o tal "contexto" no contexto de Inteligência Artificial? Similaridade entre palavras por conta do ponto anterior (Exemplo: Banana tem similaridade com maçã, pois ambas tem como "vizinhos" palavras iguais ou próximas, ou seja, "Vou ali na feira comprar banana" as palavras vizinhas são iguais para "Vou ali na feira comprar maçã", porisso essa similaridade entre elas, o contexto no qual elas estão inseridas são parecidos). Semântica (Significado) das palavras, também por conta do ponto anterior (É dado de acordo com os vizinhos). Graças a esses mecanismos o GPT consegue resumir textos por exemplo...

- Como fazer boas perguntas para obter boas respostas: A primeira camada é uma Inteligência Artificial treinada com perguntas dos próprios usuários que estão utilizando ela, então só praticando para saber, é uma melhoria contínua, mas entender esses pontos ditos aqui já vai te colocar MUITO A FRENTE!

- Como foi o treinamento do modelo: Grande maior parte dos dados são em inglês devido a qualidade de artigos científicos em inglês ser superior (Pelomenos quando o assunto é tecnologia) e a maior parte da World Wide Web (Internet) é em inglês (50%): Saber isso é essencial para entender que AS RESPOSTAS por sua natureza, vai conter forte fundamentos puxados (com viés) para a cultura Americana, como por exemplo, se perguntar para o GPT: "Quem foi o inventor do Avião". A resposta dele NÃO será o Santos Dumont que aprendemos nas escolas do Brasil, e sim: Os irmãos Wilbur e Orville Wright, que são reconhecidos como sendo os inventores em outros países e culturas, neste caso, na cultura Americana.

- Segue meu site, eu sempre faço uns projetos malucos rsrs: https://wellisonbertelli.com.br
